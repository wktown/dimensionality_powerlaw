INFO:root:architecture:AtlasNet_seed=0|task:SVD_adj_2|kind:wtA_-0.2|source:adjA_-0.2|layer:c2|pooling:PCAtrans_reshape|ret_pcs:1000
INFO:root:c2
Loading catalog from entrypoints
Loading lookup from /home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/brainscore/lookup.csv
-0.2
0.25997624946025255
0.9994461658110113
-0.2
layers:   0%|          | 0/1 [00:00<?, ?it/s]INFO:model_tools.activations.core.ActivationsExtractorHelper:Running stimuli

activations:   0%|          | 0/3200 [00:00<?, ?it/s][AINFO:model_tools.activations.core.ActivationsExtractorHelper:Running stimuli


activations:   0%|          | 0/1024 [00:00<?, ?it/s][A[A

activations:   6%|â–‹         | 64/1024 [00:00<00:12, 76.67it/s][A[A

activations:  12%|â–ˆâ–Ž        | 128/1024 [00:01<00:12, 73.61it/s][A[A

activations:  19%|â–ˆâ–‰        | 192/1024 [00:02<00:11, 73.43it/s][A[A

activations:  25%|â–ˆâ–ˆâ–Œ       | 256/1024 [00:03<00:10, 73.63it/s][A[A

activations:  31%|â–ˆâ–ˆâ–ˆâ–      | 320/1024 [00:04<00:09, 77.38it/s][A[A

activations:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 384/1024 [00:05<00:08, 77.41it/s][A[A

activations:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 448/1024 [00:06<00:08, 70.95it/s][A[A

activations:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512/1024 [00:07<00:07, 70.21it/s][A[A

activations:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 576/1024 [00:07<00:06, 70.53it/s][A[A

activations:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 640/1024 [00:08<00:05, 69.09it/s][A[A

activations:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 704/1024 [00:09<00:04, 67.33it/s][A[A

activations:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:10<00:03, 67.05it/s][A[A

activations:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 832/1024 [00:11<00:02, 65.38it/s][A[A

activations:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 896/1024 [00:12<00:02, 63.25it/s][A[A

activations:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 960/1024 [00:14<00:01, 61.23it/s][A[A

activations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:15<00:00, 59.44it/s][A[Aactivations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:15<00:00, 67.07it/s]
INFO:model_tools.activations.core.ActivationsExtractorHelper:Packaging into assembly


layer packaging:   0%|          | 0/1 [00:00<?, ?it/s][A[A

layer packaging: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.66s/it][A[Alayer packaging: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.66s/it]
imagenet dict [0] shape
(1000, 1000, 24, 24)


layer principal components:   0%|          | 0/1 [00:00<?, ?it/s][A[A

layer principal components: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.98s/it][A[Aactivations:   0%|          | 0/3200 [03:11<?, ?it/s]
layers:   0%|          | 0/1 [03:11<?, ?it/s]
Traceback (most recent call last):
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/wtownle1/dimensionality_powerlaw/scripts/fit_encoding_models.py", line 169, in <module>
    main(benchmark=benchmark, seed=args.seed, pooling=args.pooling, debug=args.debug)
  File "/home/wtownle1/dimensionality_powerlaw/utils.py", line 29, in wrap
    result = func(*args, **kwargs)
  File "/home/wtownle1/dimensionality_powerlaw/scripts/fit_encoding_models.py", line 38, in main
    layer_scores = fit_encoder(benchmark, model, layers, pooling, n_pcs)
  File "/home/wtownle1/dimensionality_powerlaw/scripts/fit_encoding_models.py", line 91, in fit_encoder
    score = model_scores(benchmark=benchmark, layers=[layer], prerun=True)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/model_tools/brain_transformation/neural.py", line 108, in __call__
    model=self._activations_model, benchmark=benchmark, layers=layers, prerun=prerun)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/result_caching/__init__.py", line 312, in wrapper
    result = function(**reduced_call_args)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/model_tools/brain_transformation/neural.py", line 122, in _call
    score = benchmark(layer_model)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/brainscore/utils/__init__.py", line 80, in __call__
    return self.content(*args, **kwargs)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/brainscore/benchmarks/_neural_common.py", line 26, in __call__
    source_assembly = candidate.look_at(stimulus_set, number_of_trials=self._number_of_trials)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/model_tools/brain_transformation/neural.py", line 143, in look_at
    self._model(layers=self._layers, stimuli=stimuli)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/model_tools/activations/pytorch.py", line 41, in __call__
    return self._extractor(*args, **kwargs)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/model_tools/activations/core.py", line 41, in __call__
    return self.from_stimulus_set(stimulus_set=stimuli, layers=layers, stimuli_identifier=stimuli_identifier)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/model_tools/activations/core.py", line 55, in from_stimulus_set
    activations = self.from_paths(stimuli_paths=stimuli_paths, layers=layers, stimuli_identifier=stimuli_identifier)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/model_tools/activations/core.py", line 73, in from_paths
    activations = fnc(layers=layers, stimuli_paths=reduced_paths)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/result_caching/__init__.py", line 312, in wrapper
    result = function(**reduced_call_args)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/model_tools/activations/core.py", line 79, in _from_paths_stored
    return self._from_paths(layers=layers, stimuli_paths=stimuli_paths)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/model_tools/activations/core.py", line 85, in _from_paths
    layer_activations = self._get_activations_batched(stimuli_paths, layers=layers, batch_size=self._batch_size)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/model_tools/activations/core.py", line 135, in _get_activations_batched
    batch_activations = hook(batch_activations)
  File "/home/wtownle1/dimensionality_powerlaw/custom_model_tools/layerPCA_modified.py", line 36, in __call__
    self._ensure_initialized(batch_activations.keys())
  File "/home/wtownle1/dimensionality_powerlaw/custom_model_tools/layerPCA_modified.py", line 190, in _ensure_initialized
    n_components=self._n_components)
  File "/home/wtownle1/env_dim/dim-powerlaw/lib/python3.7/site-packages/result_caching/__init__.py", line 223, in wrapper
    result = function(**reduced_call_args)
  File "/home/wtownle1/dimensionality_powerlaw/custom_model_tools/layerPCA_modified.py", line 267, in _pcas
    multithread=os.getenv('MT_MULTITHREAD', '1') == '1')
ValueError: not enough values to unpack (expected 4, got 1)
not modified
pca eigenvalues:
(1000, 576000)
layer principal components: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.18s/it]